Neural Computing

Topic											Lecture

Model of Neuron (Haykin, 2nd edition, p.10-23) 
Perceptron (Haykin, p.117-120) 
Perceptron’s learning algorithm (Haykin, p.135-143, 175-178) 
Multilayer perceptron (feedforward nets) (Haykin, p.156-161) 
Backpropagation (Haykin, p.161-175, 226-232) 
Problem of local minimum, adding momentum, etc. (Haykin, p.191-198) 
Regularization (Haykin, p.218-222) 
Learning evaluation and generalization (Haykin, p.205-209, 213-218) 
Self-organising maps (Haykin, p.443-466) 						5								
Support Vector Machines (Haykin, p.318-324, 329-339, lecture notes, A. Ng notes) 	6
Hopfield networks (Haykin, p.50-66, 680-696) 						5
Gibbs sampling (Haykin, p.545-550, 561-562) 						6
Boltzmann machines, Generative models (Haykin, p.558-560, 562-574) 			6
Restricted Boltzmann machines (Lecture notes)						6, 7
Contrastive Divergence (Lecture notes) 							7
Deep learning (Lecture notes) 								7
Recurrent networks (Haykin, p.732-741)							7 
Convolutional nets (lecture notes)							7 
Autoencoders (lecture notes) 								7
Backpropagation through Time (Haykin, p. 751-756, lecture notes)			7