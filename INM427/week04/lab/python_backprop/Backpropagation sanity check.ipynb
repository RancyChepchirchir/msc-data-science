{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation with two input nodes, one hidden layer node and one output node\n",
    "\n",
    "Assuming;  \n",
    "* inputs $i_{1}, i_{2}$\n",
    "* hidden node $J$ \n",
    "* output node $K$\n",
    "* target $t_{k}$\n",
    "* learning rate $\\eta$   \n",
    "* Weights $W_{ji_{1}},W_{ji_{2}},W_{jk},\\Theta_{j},\\Theta_{k}$   \n",
    "\n",
    "**Towards output**  \n",
    "\n",
    "1. Compute input potential $U_{j} $\n",
    "\n",
    "$$ U_{j} = \\Sigma_{i}(i_{i} \\cdot W_{j,i_{i}})+\\Theta_{j} $$\n",
    "\n",
    "2. Compute output (sigmoid activation function) $o_{j}$  \n",
    "\n",
    "$$o_{j} = h(U_{j}) = \\frac{1}{1+e^{-U_{j}}} $$ \n",
    "\n",
    "3. Compute $h'_{j}$  \n",
    "\n",
    "\n",
    "$$ h_{j}'(U_{j}) = \\frac{e^{-U_{j}}}{(1 + e^{-U_j})^2} $$  \n",
    "\n",
    "4. Compute input potential $U_{k}$  \n",
    "\n",
    "$$ U_{k} = (o_{j} \\cdot W_{j,k})+\\Theta_{k} $$ \n",
    "\n",
    "5. Compute output $o_{k}$  \n",
    "\n",
    "$$o_{k} = h(U_{k}) = \\frac{1}{1+e^{-U_{k}}} $$ \n",
    "\n",
    "6. Compute $h_{k}'$  \n",
    "\n",
    "$$ h_{k}'(U_{k}) = \\frac{e^{-U_{k}}}{(1 + e^{-U_k})^2} $$  \n",
    "\n",
    "7. Compute error $e_{k}$  \n",
    "\n",
    "$$ e_{k} = o_{k} - t_{k} $$\n",
    "\n",
    "**Towards input**\n",
    "\n",
    "8. Compute $\\partial o_{k}$  \n",
    "\n",
    "$$ \\partial o_{k} = e_{k} \\cdot h'(U_{k}) $$  \n",
    "\n",
    "9.  Compute error $e_{j}$  \n",
    "\n",
    "$$ e_{j} = W_{k,j} \\cdot \\partial o_{k} $$\n",
    "\n",
    "10. Compute $\\partial o_{j}$  \n",
    "\n",
    "$$ \\partial o_{j} = e_{j} \\cdot h'(U_{j}) $$  \n",
    "\n",
    "11. Compute $\\Delta W_{kj}$ \n",
    "\n",
    "$$ \\Delta W_{kj} = -\\eta \\cdot \\partial o_{k} \\cdot o_{j} $$  \n",
    "\n",
    "12. Compute $\\Delta W_{ji_{1}}$  \n",
    "\n",
    "$$ \\Delta W_{ji_{1}} = -\\eta \\cdot \\partial o_{j} \\cdot o_{i_{1}} $$  \n",
    "\n",
    "13. Compute $\\Delta W_{ji_{2}}$  \n",
    "\n",
    "$$ \\Delta W_{ji_{2}} = -\\eta \\cdot \\partial o_{j} \\cdot o_{i_{2}} $$ \n",
    "\n",
    "14. Compute $\\Delta \\Theta _{k}$  \n",
    "\n",
    "$$ \\Delta \\Theta _{k} = -\\eta \\cdot \\partial k $$  \n",
    "\n",
    "15. Compute $\\Delta \\Theta _{j}$  \n",
    "\n",
    "$$ \\Delta \\Theta _{j} = -\\eta \\cdot \\partial j $$  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=cl)\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    alpha=1.0,\n",
    "                    linewidths=1,\n",
    "                    marker='o',\n",
    "                    s=55, label='test set')\n",
    "        \n",
    "        \n",
    "import numpy\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The following code is used for hiding the warnings and make this notebook clearer.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def tanh(x):\n",
    "    return (1.0 - numpy.exp(-2*x))/(1.0 + numpy.exp(-2*x))\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return (1 + tanh(x))*(1 - tanh(x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + numpy.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    #########\n",
    "    # parameters\n",
    "    # ----------\n",
    "    # self:      the class object itself\n",
    "    # net_arch:  consists of a list of integers, indicating\n",
    "    #            the number of neurons in each layer, i.e. the network architecture\n",
    "    #########\n",
    "    def __init__(self, net_arch, af):\n",
    "        numpy.random.seed(0)\n",
    "        \n",
    "        # set activation function\n",
    "        if af == 't':\n",
    "            actF = [tanh,tanh_derivative]\n",
    "        else:\n",
    "            actF = [sigmoid,sigmoid_derivative]\n",
    "            \n",
    "        # Initialized the weights, making sure we also \n",
    "        # initialize the weights for the biases that we will add later\n",
    "        self.activity = actF[0] # tanh\n",
    "        self.activity_derivative = actF[1] # tanh_derivative\n",
    "        self.layers = len(net_arch)\n",
    "        self.steps_per_epoch = 1\n",
    "        self.arch = net_arch\n",
    "        self.weights = []\n",
    "\n",
    "        # Random initialization with range of weight values (-1,1)\n",
    "        for layer in range(self.layers - 1):\n",
    "            w = 2*numpy.random.rand(net_arch[layer] + 1, net_arch[layer+1]) - 1\n",
    "            self.weights.append(w)\n",
    "    \n",
    "    def _forward_prop(self, x):\n",
    "        y = x\n",
    "\n",
    "        for i in range(len(self.weights)-1):\n",
    "            activation = numpy.dot(y[i], self.weights[i])\n",
    "            activity = self.activity(activation)\n",
    "\n",
    "            # add the bias for the next layer\n",
    "            activity = numpy.concatenate((numpy.ones(1), numpy.array(activity)))\n",
    "            y.append(activity)\n",
    "\n",
    "        # last layer\n",
    "        activation = numpy.dot(y[-1], self.weights[-1])\n",
    "        activity = self.activity(activation)\n",
    "        y.append(activity)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def _back_prop(self, y, target, learning_rate):\n",
    "        error = target - y[-1]\n",
    "        delta_vec = [error * self.activity_derivative(y[-1])]\n",
    "\n",
    "        # we need to begin from the back, from the next to last layer\n",
    "        for i in range(self.layers-2, 0, -1):\n",
    "            error = delta_vec[-1].dot(self.weights[i][1:].T)\n",
    "            error = error*self.activity_derivative(y[i][1:])\n",
    "            delta_vec.append(error)\n",
    "\n",
    "        # Now we need to set the values from back to front\n",
    "        delta_vec.reverse()\n",
    "        \n",
    "        # Finally, we adjust the weights, using the backpropagation rules\n",
    "        for i in range(len(self.weights)):\n",
    "            layer = y[i].reshape(1, self.arch[i]+1)\n",
    "            delta = delta_vec[i].reshape(1, self.arch[i+1])\n",
    "            self.weights[i] += learning_rate*layer.T.dot(delta)\n",
    "    \n",
    "    #########\n",
    "    # parameters\n",
    "    # ----------\n",
    "    # self:    the class object itself\n",
    "    # data:    the set of all possible pairs of booleans True or False indicated by the integers 1 or 0\n",
    "    # labels:  the result of the logical operation 'xor' on each of those input pairs\n",
    "    #########\n",
    "    def fit(self, data, labels, learning_rate=0.1, epochs=100):\n",
    "        \n",
    "        # Add bias units to the input layer - \n",
    "        # add a \"1\" to the input data (the always-on bias neuron)\n",
    "        ones = numpy.ones((1, data.shape[0]))\n",
    "        Z = numpy.concatenate((ones.T, data), axis=1)\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            if (k+1) % 10000 == 0:\n",
    "                print('epochs: {}'.format(k+1))\n",
    "        \n",
    "            sample = numpy.random.randint(X.shape[0])\n",
    "\n",
    "            # We will now go ahead and set up our feed-forward propagation:\n",
    "            x = [Z[sample]]\n",
    "            y = self._forward_prop(x)\n",
    "\n",
    "            # Now we do our back-propagation of the error to adjust the weights:\n",
    "            target = labels[sample]\n",
    "            self._back_prop(y, target, learning_rate)\n",
    "    \n",
    "    #########\n",
    "    # the predict function is used to check the prediction result of\n",
    "    # this neural network.\n",
    "    # \n",
    "    # parameters\n",
    "    # ----------\n",
    "    # self:   the class object itself\n",
    "    # x:      single input data\n",
    "    #########\n",
    "    def predict_single_data(self, x):\n",
    "        val = numpy.concatenate((numpy.ones(1).T, numpy.array(x)))\n",
    "        for i in range(0, len(self.weights)):\n",
    "            val = self.activity(numpy.dot(val, self.weights[i]))\n",
    "            val = numpy.concatenate((numpy.ones(1).T, numpy.array(val)))\n",
    "        return val[1]\n",
    "    \n",
    "    #########\n",
    "    # the predict function is used to check the prediction result of\n",
    "    # this neural network.\n",
    "    # \n",
    "    # parameters\n",
    "    # ----------\n",
    "    # self:   the class object itself\n",
    "    # X:      the input data array\n",
    "    #########\n",
    "    def predict(self, X):\n",
    "        Y = numpy.array([]).reshape(0, self.arch[-1])\n",
    "        for x in X:\n",
    "            y = numpy.array([[self.predict_single_data(x)]])\n",
    "            Y = numpy.vstack((Y,y))\n",
    "        return Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction\n",
      "i1 i2 t o\n",
      "[0 0] 0 0.005303951382860608\n",
      "[0 1] 1 0.9712935737946203\n",
      "[1 0] 1 0.9687222281833928\n",
      "[1 1] 0 0.00018983081586937937\n",
      "Weights:\n",
      "[array([[ 1.93345005, -0.58051179],\n",
      "       [-1.32209046,  1.45840748],\n",
      "       [-1.30544105,  1.47097214]]), array([[-1.0012255 ],\n",
      "       [ 2.40956478],\n",
      "       [ 2.49364711]])]\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(0)\n",
    "\n",
    "# Initialize the NeuralNetwork with\n",
    "# 2 input neurons\n",
    "# 2 hidden neurons\n",
    "# 1 output neuron\n",
    "nn = NeuralNetwork([2,2,1], 't')\n",
    "\n",
    "# Set the input data\n",
    "X = numpy.array([[0, 0], [0, 1],\n",
    "                [1, 0], [1, 1]])\n",
    "\n",
    "# Set the labels, the correct results for the xor operation\n",
    "y = numpy.array([0, 1, \n",
    "                 1, 0])\n",
    "\n",
    "# Call the fit function and train the network for a chosen number of epochs\n",
    "nn.fit(X, y, epochs=3200)\n",
    "\n",
    "# Show the prediction results\n",
    "print(\"Final prediction\")\n",
    "print(\"i1 i2 t o\")\n",
    "\n",
    "i = 0;\n",
    "for s in X:\n",
    "    print(s, y[i], nn.predict_single_data(s))\n",
    "    i = i + 1;\n",
    "    \n",
    "print(\"Weights:\")\n",
    "# Six weights and 3 biases\n",
    "print(nn.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_regions(X, y, nn)\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
