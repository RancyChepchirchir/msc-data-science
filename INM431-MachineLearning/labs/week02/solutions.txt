2. Cannabis 

A - presence of cannabis
B - positive test

P(B|A) = 0.9	% positive test given the presence of cannabis
P(B|~A) = 0.1	% positive test given the absence of cannabis
P(A) = 0.2	% presence of cannabis - general driving population
P(~A) = 0.8	% absence of cannabis - general driving population

i. What is the probability that a driver has smoked cannabis in the last 72 hours if they have tested positive?

P(A|B)	% probability of presence of cannabis given a positive test

% Bayes' Theorem
P(A|B) = P(B|A) * P(A) / P(B)

% Sum rule - sum of joint probabilities P(B,A) and P(B,~A)
P(B) = P(B|A) * P(A) + P(B|~A) * P(~A)

% In plain English, probability of a positive test is equal to
% the probability of a positive test given the presence of cannabis times presence of 
% cannabis, **plus** the probability of a positive test given the absence of cannabis times
% absence of cannabis 

P(A|B) = (0.9 * 0.2) / (0.9 * 0.2 + 0.1 * 0.8)
P(A|B) = 0.6923076923 ~ 69%

ii. What is the probability that someone smoked cannabis in the last 72 hours if they have not tested positive?

P(A|~B)	% probability of presence of cannabis given a negative test result

New information: 

P(B|A) = 0.999	% positive test in the presence of cannabis
P(B|~A) = 0.2	% positive test in the absence of cannabis

% Bayes' Theorem
P(A|~B) = P(~B|A) * (A) / P(~B)
% Sum rule - all negative test cases, for presence and absence of cannabis
P(~B) = P(~B|A) * (A) + P(~B|~A) * (~A)  

We need P(~B|A) and P(~B|~A): 
P(B|A) = 0.999	% true positive
P(~B|A) = 0.001 % false negative, negative test in the presence of cannabis 
P(B|~A) = 0.2	% false positive, positive test in the absence of cannabis
P(~B|~A) = 0.8	% true negative, negative test in the absence of cannabis

P(A|~B) = (P(~B|A) * (A)) / (P(~B|A) * (A) + P(~B|~A) * (~A)) 
P(A|~B) = (0.001 * 0.2) / (0.001 * 0.2 + 0.8 * 0.8)
P(A|~B) = 0.00031240237 % 0.003% ~ 3 cases in 1k, 31 cases in 10k - inhaled?

3. X-factor

What is the probability that a vote for the winner was cast by a viewer from Dover?

P(B) = 0.46 	% from Bury, 
P(C) = 0.38	% from Croydon
P(D) = 0.16	% from Dover
NB Proportion sum = 1.

% The poll showed that 
P(W|B) = 0.61 	% given Bury viewers, percentage of winning votes 
P(W|C) = 0.88	% given Croydon viewers, percentage of winning votes 
P(W|D) = 0.51	% given Dover viewers, percentage of winning votes
NB Proportion sum ~= 1.

% P(D|W) - given a winning vote (prior), probability it was cast by a Dover viewer?

Question for Artur, is P(W|D) the likelihood and P(D|W) the posterior?

% Bayes' Theorem
P(D|W) = P(W|D) * P(D) / P(W)
P(W|D), P(D) are known.
P(W) unknown.

% Sum rule - sum of all joint probabilities:
P(W) = P(W,B) + P(W,C) + P(W,D)
P(W) = P(W|B) * P(B) + P(W|C) * P(C) + P(W|D) * P(D)
P(D|W) = (P(W|D) * P(D)) / (P(W|B) * P(B) + P(W|C) * P(C) + P(W|D) * P(D))
P(D|W) = (0.51 * 0.16) / (0.61 * 0.46 + 0.88 * 0.38 + 0.51 * 0.16) 
P(D|W) = 0.11714039621 ~ 12%

Expansion - kind of helps with problem 4
What was the voting ratio P(W):P(~W)?

% From poll it can be inferred: 
P(~W|B) = 0.39	% given Bury viewers, percentage of losing votes 
P(~W|C) = 0.12	% given Croydon viewers, percentage of losing votes 
P(~W|D) = 0.49	% given Dover viewers, percentage of losing votes

City	Winning votes	Losing votes
Bury	P(W|VB) = 0.61	P(~W|VB) = 0.39	
Croydon	P(W|VC) = 0.88	P(~W|VC) = 0.12
Dover	P(W|VD) = 0.51	P(~W|VD) = 0.49

% Sum rule
P(W) = P(W,B) + P(W,C) + P(W,D)
P(W) = P(W|B) * P(B) + P(W|C) * P(C) + P(W|D) * P(D)
P(W) = 0.61 * 0.46 + 0.88 * 0.38 + 0.51 * 0.16
P(W) = 0.6966 - 70%
P(~W) = P(~W,B) + P(~W,C) + P(~W,D)
P(~W) = P(~W|B) * P(B) + P(~W|C) * P(C) + P(~W|D) * P(D)
P(~W) = 0.39 * 0.46 + 0.12 * 0.38 + 0.49 * 0.16
P(~W) = 0.3034 ~ 30% 
P(W):P(~W) = 0.7:0.3

P(W) + P(~W) = 1
P(~W) = 1 - P(W)

What the computation shows:
Had we taken a member of the voting population at random, there is a 70% probability the
voter would have cast a winning vote and a 30% probability the voter would
have cast a losing vote.

4. Neural Networks

What are the chances that George knows what a neural network is?

P(G|AI) = 0.5	% probability George studied AI, given AI course, did George take AI - course exists (prior)
P(G|CS) = 0.2	% probability George studied CS
P(G|NS) = 0.3	% probability George did not study AI or CS - NS (no CS or AI studies - rest of population)

P(AI) = 0.8	% ratio AI students that know what a neural network is 
P(CS) = 0.4	% ratio of CS students that know what a neural network is  
P(NS) = 0.1	% ratio of NS students (rest of population) that know what a neural network is

P(G) % probability that George knows what a neural network is

% Sum rule - sum of all joint probabilities
PG = P(G,AI) + P(G,CS) + P(G,NS)
P(G) = 	P(G|AI) * P(AI) + P(G|CS) * P(CS) + P(G|NS) * P(NS) 	
P(G) = 	0.5 * 0.8 + 0.2 * 0.4 + 0.3 * 0.1
P(G) = 	0.51 ~ 51% - conversely P(~G) = 49%

This is similar to problem 4 in that, if we chose at random a member of the population being
considered, there is a 51% change that member knows what a neural network is.

5. Fake coin

P(G) = 0.999		% probability of picking a genuine coin
P(~G) = 0.001		% probability of picking a fake coin
P(Hx10|G) = 1/1024	% given a genuine coin, probability of flipping ten consecutive heads (1/2)^10
P(Hx10|~G) = 1		% given a fake coin, probability of flipping ten consecutive heads

P(~G|HX10) 		% given 10 consecutive heads, probability of coin being fake

% Bayes' Theorem
P(~G|HX10) = P(Hx10|~G) * P(~G) / P(Hx10)

% Sum rule
P(Hx10) = P(Hx10|~G) * P(~G) + P(Hx10|G) * P(G)
 
% In plain English, probability of ten consecutive heads is equal to
% the probability of flipping ten consecutive heads given a fake coin, times the 
% probability of picking a fake coin, **plus** the probability of flipping ten consecutive
% heads given a genuine coin, times the probability of picking a genuine coin.

P(~G|HX10) = (P(Hx10|~G) * P(~G)) / (P(Hx10|~G) * P(~G) + P(Hx10|G) * P(G))
P(~G|HX10) = (1 * 0.001) / (1 * 0.001 + 1/1024 * 0.999)
P(~G|HX10) = 0.50617894216 ~ 51%

Extension: All ten times fall ‘heads’. What is the probability that this coin is genuine?

P(G|HX10) = P(HX10|G) * G / P(HX10)
P(G|HX10) = P(HX10|G) * G / P(HX10|G) * G + P(HX10|~G) * ~G
P(G|HX10) = (1/1024 * 0.999) / (1/1024 * 0.999 + 1 * 0.001)
P(G|HX10) = 0.49382105783 ~ 49%

So it follows:
P(G|HX10) + P(~G|HX10) = 1

6. Prisoner's dilemma

0 = No Confession					 
1 = Confession					
W1 = You
W2 = John

W1 W2	W1 sentence W2 sentence 
0  0	1	    1
0  1	6	    0
1  0	0	    6
1  1 	3	    3

Prison sentences for W1 & W2
Turn witness 	   - average sentence 0 + 3 = 1.5 years
Don't turn witness - average sentence 1 + 6 = 3.5 years

To minimize jail sentence, best turn witness.
To maximize jail sentence, best not turn witness.