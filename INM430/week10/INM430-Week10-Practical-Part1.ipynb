{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INM430 Week 10 Practical - Part 1\n",
    "Scrape London Datastore  \n",
    "Here we build an inventory of what is available and where  \n",
    "\n",
    "Part 1 of 3 \n",
    "1. Get LDS column names\n",
    "2. Get Health data column names  \n",
    "3. Cross reference and determine scope  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def getLDSDownloadLinksPageCount():\n",
    "    # get the number of London Datastore pages we can scrape\n",
    "    # using the same general format from week 09\n",
    "    from bs4 import BeautifulSoup\n",
    "    import urllib.request as ur\n",
    "    urlToScrape = \"https://data.london.gov.uk/dataset\"\n",
    "    r = ur.urlopen(urlToScrape).read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    # looking for the paging links found near footer\n",
    "    linkList = soup.find_all('li', attrs={'class': 'dp-search__pagelink'})\n",
    "    # all being well, the list will look like this (where each line is a list element)\n",
    "    \n",
    "    #<li class=\"dp-search__pagelink dp-search__pagelink--disabled\"><span>«</span></li>\n",
    "    #<li class=\"dp-search__pagelink dp-search__pagelink--active\"><span>1</span></li>\n",
    "    #<li class=\"dp-search__pagelink\"><a href=\"/dataset?page=2\">2</a></li>\n",
    "    #<li class=\"dp-search__pagelink\"><a href=\"/dataset?page=3\">3</a></li>\n",
    "    #<li class=\"dp-search__pagelink\"><a href=\"/dataset?page=4\">4</a></li>\n",
    "    #<li class=\"dp-search__pagelink\"><span>...</span></li>\n",
    "    #<li class=\"dp-search__pagelink\"><a href=\"/dataset?page=78\">78</a></li>\n",
    "    #<li class=\"dp-search__pagelink\"><a href=\"/dataset?page=2\">»</a></li>\n",
    "    \n",
    "    # The line we are interested in is the next to last (page 78), number 78 being\n",
    "    # the text property of the link (a href attribute), which is the 6th element of\n",
    "    # the linkList list starting from index 0\n",
    "    try:\n",
    "        iPagenums = linkList[6].text\n",
    "    except:\n",
    "        # string data type for consistency\n",
    "        iPagenums = \"0\"\n",
    "\n",
    "    return int(iPagenums)\n",
    "\n",
    "def getLDSDownloadLinks(iPagenum):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import urllib.request as ur\n",
    "    urlToScrape = \"https://data.london.gov.uk/dataset?page=\" + str(iPagenum)\n",
    "    r = ur.urlopen(urlToScrape).read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    # look for h3 headers\n",
    "    linkList = soup.find_all('h3', attrs={'class': 'dp-searchresult__heading'})\n",
    "    # our return list\n",
    "    results = []\n",
    "    for linkListItem in linkList:\n",
    "        try:\n",
    "            linkHeader = linkListItem.find('a', attrs={'class': \"dp-searchresult__heading-link\"})\n",
    "            name = linkHeader.text\n",
    "            href = linkHeader['href']\n",
    "            ldslinks = {\n",
    "                \"name\" : name,\n",
    "                \"href\" : href,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(\"Error - no links found\")\n",
    "        results.append(ldslinks)\n",
    "    return results\n",
    "\n",
    "def getLDSFileDownloadLinkOld(href):\n",
    "    # get the file download link - note the link might expire\n",
    "    from bs4 import BeautifulSoup\n",
    "    import urllib.request as ur\n",
    "    urlToScrape = \"https://data.london.gov.uk\" + href\n",
    "    r = ur.urlopen(urlToScrape).read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    try:\n",
    "        downloadlink = soup.find('a', attrs={'class': 'dp-resource__link'})\n",
    "        filelink = downloadlink['href']\n",
    "    except:\n",
    "        filelink = \"\"\n",
    "    return filelink\n",
    "\n",
    "def getLDSFileDownloadLinks(href):\n",
    "    # get the file download links - pdf, xls, etc, decide later what to do\n",
    "    from bs4 import BeautifulSoup\n",
    "    import urllib.request as ur\n",
    "    href = '/dataset/london-food-strategy-consultation-2018'\n",
    "    urlToScrape = \"https://data.london.gov.uk\" + href\n",
    "    r = ur.urlopen(urlToScrape).read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    downloads = soup.find_all('div', attrs={'class': 'dp-resource__indented'})\n",
    "    fileurls = []\n",
    "    for download in downloads:\n",
    "        try:\n",
    "            links = download.find('a', attrs={'class': 'dp-resource__format'})\n",
    "            fileurl = links['href']\n",
    "            dictlinks = {\n",
    "                \"fileurl\" : fileurl,\n",
    "            }\n",
    "            fileurls.append(dictlinks)\n",
    "        except:\n",
    "            print(\"Error occured parsing file download links\")\n",
    "    return fileurls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iPagenums = getLDSDownloadLinksPageCount()\n",
    "# initialise our links dictionary\n",
    "links = []\n",
    "for i in range(1, iPagenums + 1):\n",
    "    links.extend(getLDSDownloadLinks(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-23858bf1d199>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'url'"
     ]
    }
   ],
   "source": [
    "for link in links:\n",
    "    print(link['name'],link['href'], link['url'])\n",
    "    getLDSFileDownloadLink(href)\n",
    "    # update links[0]['fileurl'] = \"stuff\"\n",
    "# can't use for loop, will have to use an index    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for i in range(1, 2):\n",
    "    links.extend(getLDSDownloadLinks(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "getLDSFileDownloadLink('/dataset/london-food-strategy-consultation-2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls\n",
      "1\n",
      "/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf\n"
     ]
    }
   ],
   "source": [
    "# get the file download links - pdf, xls, etc, decide later what to do\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as ur\n",
    "href = '/dataset/london-food-strategy-consultation-2018'\n",
    "urlToScrape = \"https://data.london.gov.uk\" + href\n",
    "r = ur.urlopen(urlToScrape).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "downloads = soup.find_all('div', attrs={'class': 'dp-resource__indented'})\n",
    "fileurls = []\n",
    "for download in downloads:\n",
    "    try:\n",
    "        links = download.find('a', attrs={'class': 'dp-resource__format'})\n",
    "        fileurl = links['href']\n",
    "        dictlinks = {\n",
    "            \"fileurl\" : fileurl,\n",
    "        }\n",
    "        fileurls.append(dictlinks)\n",
    "    except:\n",
    "        print(\"Error occured parsing file download links\")\n",
    "        \n",
    "return fileurls\n",
    "        \n",
    "for i in range(0, len(fileurls)):\n",
    "    print(str(i))\n",
    "    print(fileurls[i]['fileurl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = getLDSDownloadLinks(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Income Inequality', 'href': '/dataset/income-inequality'},\n",
       " {'name': 'HBAI Poverty in London', 'href': '/dataset/hbai-poverty'},\n",
       " {'name': 'Gender Pay Gaps in London', 'href': '/dataset/gender-pay-gaps'},\n",
       " {'name': 'Equality, Diversity and Inclusion Evidence Base for London',\n",
       "  'href': '/dataset/equality--diversity-and-inclusion-evidence-base-2018'},\n",
       " {'name': 'London Underground Performance Reports',\n",
       "  'href': '/dataset/london-underground-performance-reports'},\n",
       " {'name': 'GLA Poll Results 2018', 'href': '/dataset/gla-poll-results-2018'},\n",
       " {'name': 'Employees earning below the London Living Wage (LLW)',\n",
       "  'href': '/dataset/earning-below-llw'},\n",
       " {'name': 'Young Londoners Fund Projects',\n",
       "  'href': '/dataset/young-londoners-fund-projects'},\n",
       " {'name': 'Public Transport Journeys by Type of Transport',\n",
       "  'href': '/dataset/public-transport-journeys-type-transport'},\n",
       " {'name': 'London Food Strategy Consultation 2018',\n",
       "  'href': '/dataset/london-food-strategy-consultation-2018'}]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income Inequality /dataset/income-inequality\n",
      "HBAI Poverty in London /dataset/hbai-poverty\n",
      "Gender Pay Gaps in London /dataset/gender-pay-gaps\n",
      "Equality, Diversity and Inclusion Evidence Base for London /dataset/equality--diversity-and-inclusion-evidence-base-2018\n",
      "London Underground Performance Reports /dataset/london-underground-performance-reports\n",
      "GLA Poll Results 2018 /dataset/gla-poll-results-2018\n",
      "Employees earning below the London Living Wage (LLW) /dataset/earning-below-llw\n",
      "Young Londoners Fund Projects /dataset/young-londoners-fund-projects\n",
      "Public Transport Journeys by Type of Transport /dataset/public-transport-journeys-type-transport\n",
      "London Food Strategy Consultation 2018 /dataset/london-food-strategy-consultation-2018\n"
     ]
    }
   ],
   "source": [
    "for i in range (0, len(links)):\n",
    "    print(links[i]['name'], links[i]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(links)):\n",
    "    links[i]['fileurls'] = getLDSFileDownloadLinks(links[i]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'},\n",
       " {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getLDSFileDownloadLinks('/dataset/london-food-strategy-consultation-2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n",
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n",
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n",
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n",
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n",
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n",
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n",
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n",
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n",
      "[{'fileurl': '/download/london-food-strategy-consultation-2018/23e29736-c686-4c8a-8743-0aa23b3f8763/GLA%20consultation%20results%20-%20Unhealthy%20food%20advert%20ban.xls'}, {'fileurl': '/download/london-food-strategy-consultation-2018/723e7842-6ae5-4b2a-bf82-e146f4668838/GLA%20YouGov%20survey%20May%202018%20advert%20ban.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "for i in range (0, len(links)):\n",
    "    print(links[i]['fileurls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
